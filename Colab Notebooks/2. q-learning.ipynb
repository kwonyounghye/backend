{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dchdPUuCWMPG"},"outputs":[],"source":["# Q러닝 방법\n","import gym\n","import numpy as np\n","# 환경 생성\n","env = gym.make('FrozenLake-v0')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dkv3MxUpWMPK","executionInfo":{"status":"ok","timestamp":1657762553353,"user_tz":-540,"elapsed":6,"user":{"displayName":"영혜","userId":"12965580261662354816"}},"outputId":"727d31e7-4e59-4e50-fb09-e6eba0576aab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.],\n","       [0., 0., 0., 0.]])"]},"metadata":{},"execution_count":2}],"source":["# Q값을 저장할 테이블을 초기화\n","# rows: cell의 수\n","# cols: 이동할 수 있는 방향의 수\n","q_func = np.zeros((16, 4))\n","q_func"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-cqczWvWMPL"},"outputs":[],"source":["# 총 보상\n","total_reward = 0.0\n","# 게임 시작\n","for i_episode in range(10000):\n","    # 초기화\n","    observation = env.reset()\n","    # 현재 게임의 보상\n","    episode_reward = 0.0\n","    for t in range(100):\n","        # 1턴 실행 후의 위치를 현재 위치로 설정\n","        current_state = observation\n","        # 랜덤값이 0.1미만이면\n","        if np.random.rand() < 0.1:\n","            # 무작위로 행동을 선택함\n","            action = env.action_space.sample()\n","        else:\n","            # Q값이 최대가 되는 행동을 선택함\n","            action = np.argmax(q_func[current_state])\n","        # 1턴 실행\n","        # observatoin: , reward : 에어전트의 위치 행동의 결과로 받은 보상 게임 종료 여부 , done: ,\n","        # info: 행동을 취할 확률\n","        observation, reward, done, info = env.step(action)\n","        # Q ( 0.3, 0.99) 값 업데이트 학습률 할인율\n","        # Q 할인율을 곱하고 보상을 더한 값으로 를 업데이트\n","        q_func[current_state,action] += 0.3 * (reward + 0.99 * np.max(q_func[observation,:]) - q_func[current_state,action])\n","        # 종료\n","        if done:\n","            # 현재 게임 보상 누적 계산\n","            episode_reward += reward\n","    # 총 보상 누적 계산\n","    total_reward += episode_reward"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj2Sh-CsWMPM","executionInfo":{"status":"ok","timestamp":1657762577287,"user_tz":-540,"elapsed":10,"user":{"displayName":"영혜","userId":"12965580261662354816"}},"outputId":"4b6f95f6-1c08-47dd-9ca5-3c837fda4d71"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n","0.0001\n"]}],"source":["# 총 보상 출력\n","print(total_reward)\n","# 게임당 평균 보상 출력\n","print(total_reward/10000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bwt411npWMPN","executionInfo":{"status":"ok","timestamp":1657762577287,"user_tz":-540,"elapsed":7,"user":{"displayName":"영혜","userId":"12965580261662354816"}},"outputId":"2af5b69b-cc01-4f18-c681-abd751f3899a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0. ],\n","       [0. , 0. , 0. , 0.3],\n","       [0. , 0. , 0. , 0. ]])"]},"metadata":{},"execution_count":5}],"source":["# 학습된 Q값을 출력\n","q_func\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRVjZ93oWMPO"},"outputs":[],"source":["# 학습된 Q값을 사용하여 게임 진행\n","# 총 보상\n","total_reward = 0.0\n","# 게임 시작\n","for i_episode in range(1000):\n","    # 초기화\n","    observation = env.reset()\n","    # 현재 게임의 보상\n","    episode_reward = 0.0\n","    for t in range(100):\n","        # 1턴 실행 후의 위치를 현재 위치로 삼음\n","        current_state = observation\n","        # Q값이 최대가 되는 행동을 선택함\n","        action = np.argmax(q_func[current_state])\n","        # 1턴 실행\n","        observation, reward, done, info = env.step(action)\n","        # 종료\n","        if done:\n","            # 현재 게임 보상 누적 계산\n","            episode_reward += reward\n","        # 총 보상 누적 계산\n","        total_reward += episode_reward"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1NIeXrqWMPO","executionInfo":{"status":"ok","timestamp":1657762578252,"user_tz":-540,"elapsed":6,"user":{"displayName":"영혜","userId":"12965580261662354816"}},"outputId":"70955826-bfd4-4616-9e10-fc7e44a9340d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n","0.0\n"]}],"source":["# 총 보상 출력\n","print(total_reward)\n","# 게임당 평균 보상 출력\n","print(total_reward/1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VXH8PQveWMPP"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"}},"colab":{"name":"2. q-learning.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}